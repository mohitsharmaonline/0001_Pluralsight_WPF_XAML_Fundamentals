{\rtf1\ansi\deff0{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\*\generator Msftedit 5.41.21.2510;}\viewkind4\uc1\pard\sa200\sl276\slmult1\lang9\f0\fs22 Why WPF?\par
The old User32 and GDI 32 API's were proven, widely used and well understood. So why change these under pinning's?\par
The problem is that many things have chinged, since the core ideas behind the old user interface architecture were based into the API. microsoft works very hard to keep each new version of Windows as compatible as possible with it's predecessors. even with this fundamental and upheaval as the move from 16 bit to 32 bit in the 1990s, the goal was to make Win 32 as similar as possible to the 16 bit API's to minimize the pain of pausing applications. In theory you can have a single codebase that would compile for both 16 and 32 bit windows. now, if you have the joy of porting the applications between those worlds, you might question how easy that was in practice, but it was technically possible. it means the roots of User 32 and GDI 32 goes all the way back to the first 16 bit version of windows, which shipped in the mid 1980's. So these design decisions were made almost a quarter of a century ago . Hardware has moved a long way in that time. In particular graphics cards are completely different in nature. Back when Windows one was being designed, graphics cards were very simple devices , not much more than enough memory to remember what was on screen, plus a little bit of electronics to send the image out to the screen.\par
Since than we have seen more and more power move onto the graphics card. and today it's not unheard of machienes to have a gigabytes of memory purely on the graphics cards. That s order of magnitude more memory tham you would have in the entire machine back when Windows first shipped. And graphics cards have immensely more processing power than all PC's did 25 years ago. Initially, this worked in windows favor.  The first accelarated graphics cards were designed specifically to make Systems like Windows, OS2 and the X Windows system run faster. But the graphic cards vendors eventually found out that they could make moore money by targetting 3D accelaration and unfortunately for windows developers it means that the power of the graphic cards is unaccessible untiol you're prepared to write Open GL or Direct X code. And while many people do just that it's actualy a world of complexity and not one that integrates well with more present user interface features such as list box or data binding. The old user 32 and GDI 32 turned out not to be a good match for these new 3D oriented features. So most of the graphics cards sits unused when running more desktop applications.\par
So, one of WPFs goals is to put that power back into the reach of ordinary user interfaces. Since WPF is not tied to the old way of doing things, it can take advantage of much more of a modern graphics card's capabilities. And graphics cards are not the only thing to have changed. In recent years the old hulking, great big cathode-ray tube monitors have been almost entirely displaced by flat panels. And an interesting feature of flat panel technology is it's possible to achieve a far higher resolution. Color CRTs can't get much better than about 100 pixels per inch, which is about the same resolution as an old nine pin dot matrix printer, if you're old enough to remember those. Whereas you've been able to get 200 pixels per inch flat panels for a few years now, and in theory, they can go higher than that. Moreover, each pixel in a flat panel has three pieces to make up the red, green and blue color elements, and these are usually arranged as three horizontal stripes. This means that the effective horizontal resolution is actually up to 600 pixels per inch. If you adjust the color pixels of the bands of shapes to get finer controls over where the edges appear to be at least, and this is the trick that clear type uses and Mac OS10 does a very similar thing with its font rendering. This is significant because once you get beyond about 300 pixels per inch your eyes stop seeing the pixels and just see the shapes. This is why the first laser printers were all 300 dots per inch. It turns out to be a magic resolution. The only reason laser printers with much higher resolution exist at all is because laser printers can't do shades of grey an d have to use ticks to provide the illusion of variable tone, and these tricks happen to work better with higher resolutions. \par
So why don't we all have these high resolution flat panel screens? They should look fabulous so it seems amazing that they haven't taken off. Well one reason is they are crippling expensive, but that's really only the result of the lack of demand. So why is the demand so low? It's mainly because current operating systems don't work that well with them. Most desktop software and this is not just a Windows problem by the way, most desktop software assumes that pixels are roughly a certain size and if you plug in a screen that has a high pixel density, each pixel is smaller, and so the user interface shrinks. And that's the problem with exotics 200 DPI displays. Applications running on them are so small that they're almost unusable. To be fair to Windows it is possible to write an application that scales itself according to the pixel size of the display. The problem is nobody bothers. \par
Historically, this is because all displays used to have roughly the same pixel size so why would anyone spend time and money developing software that could support screen technology that didn't actually exist. And now that it does exist, none of the software out there supports it, so no one buys the things. \par
WPF is aiming to break this cycle. WPF applications are automatically scalable. Unlike in Win 32, a WPF developer does not have to take any special steps to make an application DPI aware. In fact, you'd have to go out of your way to make a WPF that wasn't able to adapt to variable pixel sizes. \par
So scalability in terms of screen resolution comes naturally in WPF applications without extra efforts. so they are much better placed to take advantage of High DPI screens should they ever become affordable. \par
 It is not just the hardware that has moved on in 25 years. User's expectations have changed as well. Back in the 1980s, it was acceptable to produce character mode applications. Indeed many people thought that this whole window idea was a bit frivolous, a bit of a case of style over substance. But today, character driven user interface is increasingly something of a relic. These are still popular on UNIX platforms amongst users sufficiently techy or into like using command lines, but the norm technical audiences, character based user interfaces are no longer acceptable. Users expect either a web or a window user interface. Now we're all used to seeing the cool but rather stupid user interfaces on television and in the movies. For example, there's the search user interface which seems to show a picture of every known felon during the search for some reason, and the user interface itself may well be suspended in space. This looks cool although it does require end users to develop massive upper body strength and stamina because they've got to have their hands in the air all day to operate the software. \par
Of course we know it's not real. The goal is simply not to let the carefully crafted visual style of the program or movie to come crashing down by showing some clinking real user interfaces. Technical audiences are simply asked to suspend their disbelief in the name of aesthetics. \par
Except games consoles went and made it real. Any modern game will present a user interface that is fully integrated into the look of the production. But unlike the UIs that we see in films and on television, the ones in games actually work. And we expect this. If you shell out cash for a game you'd be disappointed if its main user interface was in the battle ship grey style of boring Windows applications beloved of line of business developers. And in fact it's not just games that have moved the state of the visual art of application design forward. Websites are usually branded these days.\par
 When we visit a company website, we expect it to look like it's part of the company. Which means using a design consistent with that company's brochures, advertising and any other visual medium through with the company presents itself. And sites that don't bother with this design look amateurish these days. And now that the web has set these expectations, people are coming to expect it with intranet sites as well as public ones. Plenty of companies put a lot of effort into making their internal websites, sites that may never be seen by their customers, look consistent with the overall brand of the company. Classic Windows applications have been left behind. They started to look rather like 80 by 24 character mode applications dated in the 1990s. Tolerable, but a strange throwback in an otherwise more appealing world. Part of the reason for this is that it's just harder to build, design and branding into a Windows application than it is to a web application. And this is largely due to HTML. \par
HTML enabled someone with no software development skills to create a user interface, either by writing HTML directly or using a tool that speaks that language. But if your user interface technology requires you to be able to write a wndproc to get something to appear on screen, then the chances of finding people who have the skills to make the application appear, and make it look nice, are vanishingly small. \par
So WPF aims to solve this problem in a similar way to the web, by providing a mark-up language. XAML, it makes it possible for norm developer tools to be created letting visual designers become more directly involved in the creation of applications.\par
 Indeed the idea is to provide designers with considerable more power than they would have had in a web application, enabling Windows apps not only to catch up with where the web has been for a few years, but to move things forward.\par
}
 